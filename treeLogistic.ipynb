{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import treelib\n",
    "import itertools\n",
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,branches=None,attribute=None,threshold=None,value=None):\n",
    "        if branches is None and value is None:\n",
    "            print(\"ERROR\")\n",
    "        \n",
    "        self.branches = branches\n",
    "        self.threshold = threshold\n",
    "        self.attribute = attribute\n",
    "        self.is_leaf = True if self.branches is None else False\n",
    "        self.value = value\n",
    "        self.pinfo = {}\n",
    "        \n",
    "    def get_child(self,df):\n",
    "        if isinstance(df[self.attribute],(int,float,np.number)):\n",
    "            return self.branches[0] if df[self.attribute] < self.threshold else self.branches[1]\n",
    "        else:\n",
    "            return self.branches[0] if df[self.attribute] in self.threshold else self.branches[1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree:\n",
    "    def __init__(self,root):\n",
    "        self.root = root\n",
    "        \n",
    "    def predict(self,x):\n",
    "        item = self.root\n",
    "        while not item.is_leaf:\n",
    "            item = item.get_child(x)\n",
    "        return item\n",
    "    \n",
    "    def leaf_count(self):\n",
    "        return self._leaf_count(self.root)\n",
    "    \n",
    "    def _leaf_count(self,node):\n",
    "        if node.is_leaf:\n",
    "            return 1\n",
    "        else:\n",
    "            return np.sum([self._leaf_count(b) for b in node.branches])\n",
    "    \n",
    "    def nodes(self):\n",
    "        return self._nodes(self.root)\n",
    "    \n",
    "    def _nodes(self,node):\n",
    "        if node.is_leaf:\n",
    "            return [node]\n",
    "        \n",
    "        nl = [node]\n",
    "        for b in node.branches:\n",
    "            nl += self._nodes(b)\n",
    "        return nl\n",
    "    \n",
    "    def classes(self):\n",
    "        nodes = self.nodes()\n",
    "        c = []\n",
    "        for n in nodes:\n",
    "            c.append(n.value)\n",
    "        return np.unique(c).tolist()\n",
    "    \n",
    "    def show(self):\n",
    "        tree_view = treelib.Tree()\n",
    "        self._show(self.root,tree_view)\n",
    "        tree_view.show()\n",
    "        \n",
    "    def _show(self,node,tree_view,parent=None,prefix=\"\"):\n",
    "        name = str(hash(node))\n",
    "        if node.is_leaf:\n",
    "            text = f\"{prefix}{node.value}\"\n",
    "        else:\n",
    "            if isinstance(node.threshold,(int,float,np.number)):\n",
    "                text = f\"{prefix}{node.attribute}<{node.threshold:.2f}\"\n",
    "            else:\n",
    "                text = f\"{prefix}{node.attribute} in {node.threshold}\"\n",
    "        tree_view.create_node(text,name,parent=parent)\n",
    "        \n",
    "        if not node.is_leaf:\n",
    "            for i, b in enumerate(node.branches):\n",
    "                p = \"True: \" if i == 0 else \"False:\"\n",
    "                self._show(b,tree_view,parent=name,prefix=p)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Node and Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "young\n"
     ]
    }
   ],
   "source": [
    "l0= Node(value=\"young\")\n",
    "l1=Node(value=\"old\")\n",
    "r=Node([l0,l1],\"age\",18)\n",
    "t=Tree(r)\n",
    "print(t.predict({\"age\":2}).value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old\n"
     ]
    }
   ],
   "source": [
    "print(t.predict({\"age\":20}).value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.leaf_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Node at 0x7f9a107aff90>,\n",
       " <__main__.Node at 0x7f9a107afd50>,\n",
       " <__main__.Node at 0x7f9a107afe50>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification And Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CART:\n",
    "    def __init__(self,df,y_name,X_names=None,min_leaf_samples=1,min_split_samples=1,max_depth=32767):\n",
    "        self.y_name = y_name\n",
    "        if X_names is None:\n",
    "            X_names = list(df.columns)\n",
    "            X_names.remove(self.y_name)\n",
    "        self.X_names = X_names\n",
    "        self.df = self._handle_missings(df)\n",
    "        self.tree = None\n",
    "        self.splittyness = 1.\n",
    "        self.leaf_loss_threshold = 1e-12\n",
    "        \n",
    "        self.classes = np.unique(df[self.y_name]).tolist()\n",
    "        \n",
    "        self.min_leaf_samples = min_leaf_samples\n",
    "        self.min_split_samples = min_split_samples\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        self.depth = 0\n",
    "        \n",
    "    def train(self,k=5, plot=True, slack=1.):\n",
    "        \"\"\"\n",
    "        train desicion tree by k-fold cross-validation\n",
    "        \"\"\"\n",
    "        #shuffle dataframe\n",
    "        df = self.df.sample(frac=1.)\n",
    "        \n",
    "        # train tree with full dataset\n",
    "        self.create_tree()\n",
    "        pres = self.prune()\n",
    "        beta = self._beta(pres[\"alpha\"])\n",
    "        qual_cv = np.zeros((len(beta),k))\n",
    "        #split df for k-fold cross-validation\n",
    "        training_sets, test_sets = self._k_fold_split(df,k)\n",
    "        for i in range(len(training_sets)):\n",
    "            c = CART(training_sets[i],\n",
    "                     self.y_name,\n",
    "                     X_names = self.X_names, \n",
    "                     min_leaf_samples=self.min_leaf_samples,\n",
    "                     min_split_samples=self.min_split_samples,\n",
    "                     max_depth=self.max_depth)\n",
    "            c.create_tree()          \n",
    "            pres = c.prune(test_set=test_sets[i])\n",
    "            qual = self._qualities(beta,pres)\n",
    "            qual_cv[:,i] = np.array(qual)\n",
    "        qual_mean = np.mean(qual_cv, axis=1)\n",
    "        qual_sd = np.std(qual_cv, axis = 1)\n",
    "        qual_sd_mean = np.mean(qual_sd)\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.errorbar(beta,qual_mean,yerr=qual_sd)\n",
    "        \n",
    "        qual_max = np.nanmax(qual_mean)\n",
    "        ind_max = np.argmax(qual_mean)\n",
    "        qual_max_sd = qual_sd[ind_max]\n",
    "        qual_upper = qual_mean + qual_sd * slack\n",
    "        ind_best = ind_max\n",
    "        for i in range(ind_max, len(qual_upper)):\n",
    "            if qual_mean[i] > qual_max - qual_max_sd * slack:\n",
    "                ind_best = i\n",
    "        beta_best = beta[ind_best]\n",
    "        print(f\"beta_best: {beta_best}\")\n",
    "        self.create_tree()\n",
    "        self.prune(alpha_max=beta_best)\n",
    "    \n",
    "    def _beta(self,alpha):\n",
    "        beta = []\n",
    "        for i in range(len(alpha)-1):\n",
    "            if alpha[i] <= 0:\n",
    "                continue\n",
    "            b = np.sqrt(alpha[i]*alpha[i+1])\n",
    "            beta.append(b)\n",
    "        return beta\n",
    "            \n",
    "    def _quality_at(self,b,data):\n",
    "        for i, a in enumerate(data[\"alpha\"]):\n",
    "            if a > b:\n",
    "                return data[\"A_cv\"][i-1]\n",
    "        return 0.\n",
    "    \n",
    "    def _qualities(self,beta,data):\n",
    "        return [self._quality_at(b,data) for b in beta]\n",
    "    \n",
    "    @staticmethod\n",
    "    def _k_fold_split(df,k):\n",
    "        N = len(df.index)\n",
    "        n = int(np.ceil(N/k))\n",
    "        training_sets = []\n",
    "        test_sets = []\n",
    "        for i in range(k):\n",
    "            test = df.iloc[i*n:min(N,(i+1)*n),:]\n",
    "            training = df.loc[df.index.difference(test.index),:]\n",
    "            test_sets.append(test)\n",
    "            training_sets.append(training)\n",
    "        return training_sets, test_sets\n",
    "    \n",
    "    def _handle_missings(self,df_in):\n",
    "        df_out = df_in.dropna(subset=[self.y_name])\n",
    "        # use nan as category\n",
    "        # use mean if numerical\n",
    "        for name in self.X_names:\n",
    "            if np.issubdtype(df_out[name].values.dtype, np.number):\n",
    "                df_out[name] = df_out[name].fillna(np.nanmean(df_out[name].values))\n",
    "            else:\n",
    "                df_out[name] = df_out[name].fillna(\"missing\")\n",
    "        return df_out\n",
    "        \n",
    "    def create_tree(self, leaf_loss_threshold=1e-12):\n",
    "        self.leaf_loss_threshold = leaf_loss_threshold\n",
    "        root = self._node_or_leaf(self.df)\n",
    "        self.tree = Tree(root)\n",
    "        n_leafs = self.tree.leaf_count()\n",
    "        print(f\"A tree with {n_leafs} leafs was created\")\n",
    "        return self.tree\n",
    "    \n",
    "    def _gini_impurity(self, df):\n",
    "        unique, counts = np.unique(df[self.y_name].values, return_counts=True)\n",
    "        N = df[self.y_name].values.ravel().size\n",
    "        p = counts/N\n",
    "        #print(unique)\n",
    "        #print(p)\n",
    "        return 1. - np.sum(p**2)\n",
    "    \n",
    "    def _shannon_entropy(self,df):\n",
    "        unique, counts = np.unique(df[self.y_name].values, return_counts=True)\n",
    "        N = df[self.y_name].values.size\n",
    "        p = counts/N\n",
    "        return -np.sum(p * np.log2(p))\n",
    "    \n",
    "    def _misclassification_cost(self,df):\n",
    "        y = df[self.y_name].values\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        N = y.size\n",
    "        p = np.max(counts)/N\n",
    "        return 1. - p\n",
    "    \n",
    "    def _logistic_loss(self,df):\n",
    "        y = df[self.y_name].values\n",
    "        #unique, counts = np.unique(y, return_counts= True)\n",
    "        #count_max = np.max(counts)\n",
    "        p_ = self._node_value(df) #np.nanmax(counts)/np.sum(counts)\n",
    "        p_ = np.clip(p_,1e-12,1.-1e-12)\n",
    "        p = np.ones_like(y) * p_\n",
    "        l = np.sum(-y*np.log(p)-(1-y)*np.log(1-p))\n",
    "        return l\n",
    "    \n",
    "    def _residual(self,df):\n",
    "        y = df(self.y_name).values\n",
    "        p_ = self._probability(df)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _node_value(self,df):\n",
    "        return self._probability(df)\n",
    "    \n",
    "    def _majority_class(self,df):\n",
    "        y = df[self.y_name].values\n",
    "        unique, counts = np.unique(y,return_counts=True)\n",
    "        ind_max = np.argmax(counts)\n",
    "        return unique[ind_max]\n",
    "    \n",
    "    def _odds(self,df):\n",
    "        y = df[self.y_name].values\n",
    "        unique, counts = np.unique(y, return_counts=True)\n",
    "        d={0:0,1:0}\n",
    "        for i, u in enumerate(unique):\n",
    "            d[u] = counts[i]\n",
    "        if d[0] == 0:\n",
    "            return 1e12\n",
    "        odds = d[1]/d[0]\n",
    "        return odds\n",
    "    \n",
    "    def _log_odds(self,df):\n",
    "        logodds = self._odds(df)\n",
    "        logodds = np.clip(logodds,1e-12,1e12)\n",
    "        #print(f\"logodds: {logodds}\")\n",
    "        return logodds\n",
    "    \n",
    "    def _probability(self,df):\n",
    "        odds = self.odds(df)\n",
    "        p = odds/(1+odds)\n",
    "        print(f\"probability: {p}\")\n",
    "        return p\n",
    "           \n",
    "    def _opt_fun(self,df,split_name):\n",
    "        def fun(x):\n",
    "            split_df = [df[df[split_name]<x],\n",
    "                        df[df[split_name]>=x]]\n",
    "            N = len(df.index)\n",
    "            n = [len(df_.index) for df_ in split_df]\n",
    "            return n[0]/N * self._loss(split_df[0]) + n[1]/N * self._loss(split_df[1])\n",
    "        return fun\n",
    "        \n",
    "    def _node_or_leaf(self,df):\n",
    "        loss_parent = self._loss(df)\n",
    "        if (False#loss_parent < self.leaf_loss_threshold\n",
    "            or len(df.index) < self.min_leaf_samples\n",
    "            or self.depth > self.max_depth):\n",
    "            return self._leaf(df)\n",
    "        \n",
    "        loss_best, split_df, split_threshold, split_name = self._loss_best(df)\n",
    "        print(f\"Computed split:\\nloss: {loss_best:.2f} (parent: {loss_parent:.2f})\\nattribute: {split_name}\\nthreshold: {split_threshold}\\ncount: {[len(df_.index) for df_ in split_df]}\")\n",
    "        if loss_best < loss_parent:\n",
    "            #print(f\"=> Node({split_name}, {split_threshold})\")\n",
    "            branches = []\n",
    "            self.depth += 1\n",
    "            for i in range(2):\n",
    "                branches.append(self._node_or_leaf(split_df[i]))  \n",
    "            self.depth -= 1\n",
    "            unique, counts = np.unique(df[self.y_name], return_counts=True)\n",
    "            value = self._node_value(df)\n",
    "            item = Node(branches=branches,attribute=split_name,threshold=split_threshold,value=value)\n",
    "            item.pinfo[\"N\"] = len(df.index)\n",
    "            item.pinfo[\"r\"] = self._misclassification_cost(df)\n",
    "            item.pinfo[\"R\"] = item.pinfo[\"N\"]/len(self.df.index) * item.pinfo[\"r\"]\n",
    "        else:\n",
    "            item = self._leaf(df)\n",
    "            \n",
    "        return item\n",
    "    \n",
    "    def _leaf(self,df):\n",
    "        #unique, counts = np.unique(df[self.y_name].values,return_counts=True)\n",
    "        #print([(unique[i], counts[i]) for i in range(len(counts))])\n",
    "        #sort_ind = np.argsort(-counts)\n",
    "        value = self._node_value(df)#unique[sort_ind[0]]\n",
    "        leaf = Node(value=value)\n",
    "        \n",
    "        leaf.pinfo[\"N\"] = len(df.index)\n",
    "        leaf.pinfo[\"r\"] = self._misclassification_cost(df)\n",
    "        leaf.pinfo[\"R\"] = leaf.pinfo[\"N\"]/len(self.df.index) * leaf.pinfo[\"r\"]\n",
    "        #print(f\"=> Leaf({value}, N={len(df.index)})\")\n",
    "        return leaf\n",
    "    \n",
    "    def _loss_best(self,df):\n",
    "        loss = np.Inf\n",
    "        split_df = None\n",
    "        split_threshold = None\n",
    "        split_name = None\n",
    "        for name in self.X_names:\n",
    "            loss_ = np.Inf\n",
    "            if np.issubdtype(df[name].values.dtype, np.number):\n",
    "                loss_, split_df_, split_threshold_ = self._split_by_number(df,name)\n",
    "            else:\n",
    "                loss_, split_df_, split_threshold_ = self._split_by_class(df,name)\n",
    "            #print(loss_)\n",
    "            if (loss_ < loss\n",
    "                and np.min([len(df_.index) for df_ in split_df_]) >= self.min_split_samples):\n",
    "                loss = loss_\n",
    "                split_threshold = split_threshold_\n",
    "                split_df = split_df_\n",
    "                split_name = name\n",
    "\n",
    "        return loss, split_df, split_threshold, split_name\n",
    "    \n",
    "    def _split_by_number(self,df,name):\n",
    "        res = opt.minimize_scalar(self._opt_fun(df,name),bounds=(df[name].min(),df[name].max()),method=\"bounded\")\n",
    "        split_threshold = res.x\n",
    "        split_df = [df[df[name]<split_threshold],\n",
    "                    df[df[name]>=split_threshold]]\n",
    "        loss = res.fun\n",
    "        return loss, split_df, split_threshold\n",
    "    \n",
    "    def _split_by_class(self,df,name):\n",
    "        unique = np.unique(df[name])\n",
    "        comb = []\n",
    "        if len(unique) > 5:\n",
    "            comb = [(u,) for u in unique]\n",
    "        else:\n",
    "            for i in range(1,len(unique)):\n",
    "                comb += list(itertools.combinations(unique,i))\n",
    "            \n",
    "        if len(comb) < 1:\n",
    "            return np.Inf, None, None\n",
    "        \n",
    "        loss_ = np.Inf\n",
    "        loss = np.Inf\n",
    "        for c in comb:\n",
    "            split_threshold_ = c\n",
    "            split_df_ =[df[df[name].isin(split_threshold_)],\n",
    "                        df[~df[name].isin(split_threshold_)]]\n",
    "            N = len(df.index)\n",
    "            n = [len(df_.index) for df_ in split_df_]\n",
    "            loss_ = n[0]/N * self._loss(split_df_[0]) + n[1]/N * self._loss(split_df_[1])\n",
    "            if loss_ < loss:\n",
    "                loss = loss_\n",
    "                split_threshold = split_threshold_\n",
    "                split_df = split_df_\n",
    "        return loss, split_df, split_threshold\n",
    "    \n",
    "    def _loss(self,df):\n",
    "        #return self._gini_impurity(df)\n",
    "        #return self._shannon_entropy(df)\n",
    "        l = self._logistic_loss(df)\n",
    "        #print(l)\n",
    "        return l\n",
    "    \n",
    "    def metrics(self,df=None):\n",
    "        confmat = self.confusion_matrix(df=df)\n",
    "        P = self._precision(confmat)\n",
    "        #print(f\"precision: {P}\")\n",
    "        R = self._recall(confmat)\n",
    "        #print(f\"recall: {R}\")\n",
    "        F = np.mean(self._F1(P,R))\n",
    "        #print(f\"F-score: {F}\")\n",
    "        A = self._accuracy(confmat)\n",
    "        return {\"precision\":P,\n",
    "                \"recall\":R,\n",
    "                \"F-score\":F,\n",
    "                \"accuracy\":A}\n",
    "    \n",
    "    def prune(self,alpha_max=None, test_set=None):\n",
    "        #if not alpha_max:\n",
    "        #    tree = copy.deepcopy(self.tree)\n",
    "        #else:\n",
    "        tree = self.tree\n",
    "                \n",
    "        d={}\n",
    "        d[\"alpha\"]=[]\n",
    "        d[\"R\"]=[]\n",
    "        d[\"n_leafs\"]=[]\n",
    "        if test_set is not None:\n",
    "            d[\"A_cv\"] = []\n",
    "            d[\"R_cv\"] = []\n",
    "            d[\"P_cv\"] = []\n",
    "            d[\"F_cv\"] = []\n",
    "        n_iter = 0\n",
    "        g_min = 0\n",
    "        alpha = 0\n",
    "        #print(\"n_leafs\\tR\\talpha\")\n",
    "        n_leafs, R = self._g2(tree.root)\n",
    "        #print(f\"{n_leafs}\\t{R:.4f}\\t{g_min:.2e}\")\n",
    "        while tree.leaf_count() > 1 and n_iter < 100:\n",
    "            n_iter += 1\n",
    "            \n",
    "            alpha = g_min\n",
    "            if alpha_max is not None and alpha > alpha_max:\n",
    "                break\n",
    "            # compute g\n",
    "            nodes = tree.nodes()\n",
    "            g = []\n",
    "            pnodes = []\n",
    "            for n in nodes:\n",
    "                if not n.is_leaf:\n",
    "                    g.append(self._g(n))\n",
    "                    pnodes.append(n)\n",
    "                    \n",
    "            g_min = max(0,np.min(g))\n",
    "            for i, n in enumerate(pnodes):\n",
    "                if g[i] <= g_min:\n",
    "                    n.is_leaf = True\n",
    "            N, R = self._g2(tree.root)\n",
    "            #print(f\"{N}\\t{R:.4f}\\t{alpha:.2e}\")\n",
    "            if test_set is not None:\n",
    "                metrics = self.metrics(df=test_set)\n",
    "                d[\"A_cv\"].append(metrics[\"accuracy\"])\n",
    "                d[\"R_cv\"].append(metrics[\"recall\"])\n",
    "                d[\"P_cv\"].append(metrics[\"precision\"])\n",
    "                d[\"F_cv\"].append(metrics[\"F-score\"])\n",
    "            d[\"alpha\"].append(alpha)\n",
    "            d[\"n_leafs\"].append(N)\n",
    "            d[\"R\"].append(R)\n",
    "        return d\n",
    "            \n",
    "    \n",
    "    def _g(self,node):\n",
    "        n_leafs, R_desc = self._g2(node)\n",
    "        R = node.pinfo[\"R\"]\n",
    "        #print(n_leafs, R, R_desc)\n",
    "        return (R - R_desc)/(n_leafs - 1)\n",
    "                              \n",
    "    def _g2(self,node):\n",
    "        n_leafs = 0\n",
    "        R_desc = 0\n",
    "        if node.is_leaf:\n",
    "            return 1, node.pinfo[\"R\"]\n",
    "        \n",
    "        for b in node.branches:\n",
    "            nl, R = self._g2(b)\n",
    "            n_leafs += nl\n",
    "            R_desc += R\n",
    "        return n_leafs, R_desc\n",
    "    \n",
    "    def confusion_matrix(self,df=None):\n",
    "        if df is None:\n",
    "            df = self.df\n",
    "        unique = np.unique(self.df[self.y_name].values)\n",
    "        classes = unique.tolist()#self.tree.classes()\n",
    "        n_classes = len(classes)\n",
    "        confmat = np.zeros((n_classes,n_classes))\n",
    "        \n",
    "        for i in range(len(df.index)):\n",
    "            val_pred = self.tree.predict(df.iloc[i]).value\n",
    "            val_true = df[self.y_name].iloc[i]\n",
    "            i_pred = classes.index(val_pred)\n",
    "            i_true = classes.index(val_true)\n",
    "            confmat[i_true,i_pred] += 1\n",
    "        return confmat\n",
    "           \n",
    "    @staticmethod\n",
    "    def _precision(m):\n",
    "        return np.diag(m) / np.sum(m, axis=1)\n",
    "        \n",
    "    @staticmethod\n",
    "    def _recall(m):\n",
    "        return np.diag(m) / np.sum(m, axis=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _F1(P,R):\n",
    "        #F = np.zeros_like(P)\n",
    "        #for i in range(len(\n",
    "        return 2 * P * R / (P + R)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _accuracy(m):\n",
    "        return np.sum(np.diag(m))/np.sum(np.sum(m))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Owen Harris Braund</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. John Bradley (Florence Briggs Thayer) Cum...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Laina Heikkinen</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. Jacques Heath (Lily May Peel) Futrelle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. William Henry Allen</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Rev. Juozas Montvila</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Miss. Margaret Edith Graham</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Catherine Helen Johnston</td>\n",
       "      <td>female</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Karl Howell Behr</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Patrick Dooley</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass                                               Name  \\\n",
       "0           0       3                             Mr. Owen Harris Braund   \n",
       "1           1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
       "2           1       3                              Miss. Laina Heikkinen   \n",
       "3           1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
       "4           0       3                            Mr. William Henry Allen   \n",
       "..        ...     ...                                                ...   \n",
       "882         0       2                               Rev. Juozas Montvila   \n",
       "883         1       1                        Miss. Margaret Edith Graham   \n",
       "884         0       3                     Miss. Catherine Helen Johnston   \n",
       "885         1       1                               Mr. Karl Howell Behr   \n",
       "886         0       3                                 Mr. Patrick Dooley   \n",
       "\n",
       "        Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \n",
       "0      male  22.0                        1                        0   7.2500  \n",
       "1    female  38.0                        1                        0  71.2833  \n",
       "2    female  26.0                        0                        0   7.9250  \n",
       "3    female  35.0                        1                        0  53.1000  \n",
       "4      male  35.0                        0                        0   8.0500  \n",
       "..      ...   ...                      ...                      ...      ...  \n",
       "882    male  27.0                        0                        0  13.0000  \n",
       "883  female  19.0                        0                        0  30.0000  \n",
       "884  female   7.0                        1                        2  23.4500  \n",
       "885    male  26.0                        0                        0  30.0000  \n",
       "886    male  32.0                        0                        0   7.7500  \n",
       "\n",
       "[887 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic = pd.read_csv(\"titanic.csv\")\n",
    "df_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'Siblings/Spouses Aboard',\n",
       "       'Parents/Children Aboard', 'Fare'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CART' object has no attribute 'odds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_175/101893863.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mc_titanic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCART\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_titanic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Survived\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Pclass\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Age\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Fare\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Siblings/Spouses Aboard\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Sex\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Parents/Children Aboard\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_leaf_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_split_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mc_titanic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_175/1075357079.py\u001b[0m in \u001b[0;36mcreate_tree\u001b[0;34m(self, leaf_loss_threshold)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaf_loss_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaf_loss_threshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleaf_loss_threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node_or_leaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mn_leafs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaf_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_175/1075357079.py\u001b[0m in \u001b[0;36m_node_or_leaf\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_node_or_leaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mloss_parent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         if (False#loss_parent < self.leaf_loss_threshold\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_leaf_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_175/1075357079.py\u001b[0m in \u001b[0;36m_loss\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;31m#return self._gini_impurity(df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;31m#return self._shannon_entropy(df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logistic_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;31m#print(l)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_175/1075357079.py\u001b[0m in \u001b[0;36m_logistic_loss\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m#unique, counts = np.unique(y, return_counts= True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m#count_max = np.max(counts)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mp_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#np.nanmax(counts)/np.sum(counts)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0mp_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1e-12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mp_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_175/1075357079.py\u001b[0m in \u001b[0;36m_node_value\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_node_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_majority_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_175/1075357079.py\u001b[0m in \u001b[0;36m_probability\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0modds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0modds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0modds\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0modds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"probability: {p}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CART' object has no attribute 'odds'"
     ]
    }
   ],
   "source": [
    "\n",
    "c_titanic = CART(df_titanic,\"Survived\",[\"Pclass\",\"Age\",\"Fare\",\"Siblings/Spouses Aboard\",\"Sex\",\"Parents/Children Aboard\"], min_leaf_samples=5, min_split_samples=4)\n",
    "c_titanic.create_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c_titanic.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_titanic.prune()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_titanic.create_tree()\n",
    "c_titanic.prune(alpha_max=1.7e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_titanic.tree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_titanic.metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_titanic.train(slack=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_titanic.tree.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_titanic.metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
