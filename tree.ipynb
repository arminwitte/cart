{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "file_extension": ".sqlite3-console",
      "mimetype": "text/x-sqlite3-console",
      "name": "sqlite3",
      "version": "0.4.0"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport scipy.optimize as opt",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "class Leaf:\n    def __init__(self,value):\n        self.value = value",
      "metadata": {
        "tags": [],
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "class Node:\n    def __init__(self,branches,attribute,threshold):\n        self.branches = branches\n        self.threshold = threshold\n        self.attribute = attribute\n        \n    def get(self,df):\n        if isinstance(df[self.attribute],(int,float)):\n            return self.branches[0] if df[self.attribute] < self.threshold else self.branches[1]\n        else:\n            return self.branches[0] if df[self.attribute] in self.threshold else self.branches[1]\n        ",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "class Tree:\n    def __init__(self,root):\n        self.root = root\n        \n    def predict(self,x):\n        item = self.root\n        while isinstance(item,Node):\n            item = item.get(x)\n        return item",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "r=Node([Leaf('young'),Leaf('old')],\"age\",18)\nt=Tree(r)\nprint(t.predict({\"age\":2}).value)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "print(t.predict({\"age\":20}).value)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "class CART:\n    def __init__(self,df,y_name,X_names):\n        self.df = df\n        self.y_name = y_name\n        self.X_names = X_names\n        self.tree = None\n        self.splittyness = 1.\n        self.leaf_loss_threshold = 1e-12\n        \n        self.classes = np.unique(df[self.y_name]).tolist()\n        n = len(self.classes)\n        self.confusion_matrix = np.zeros((n,n))\n        \n    def create_tree(self,splittyness=1., leaf_loss_threshold=1e-12):\n        self.splittyness = splittyness\n        self.leaf_loss_threshold = leaf_loss_threshold\n        root = self._node_or_leaf(self.df)\n        self.tree = Tree(root)\n        return self.tree\n    \n    def _gini_impurity(self, df):\n        unique, counts = np.unique(df[self.y_name].values, return_counts=True)\n        N = df[self.y_name].values.ravel().size\n        p = counts/N\n        #print(unique)\n        #print(p)\n        return 1. - np.sum(p**2)\n    \n    def _shannon_entropy(self,df):\n        unique, counts = np.unique(df[self.y_name].values, return_counts=True)\n        N = df[self.y_name].values.size\n        p = counts/N\n        if p <= 0.:\n            H = 0\n        else:\n            H = -np.sum(p * np.log2(p))\n        return H\n        \n    def _opt_fun(self,df,split_name):\n        def fun(x):\n            split_df = [df[df[split_name]<x],\n                        df[df[split_name]>=x]]\n            return self._loss(split_df[0]) + self._loss(split_df[1])\n        return fun\n        \n    def _node_or_leaf(self,df):\n        loss_parent = self._loss(df)\n        if loss_parent < self.leaf_loss_threshold:\n            return self._leaf(df)\n        \n        loss_best, split_df, split_threshold, split_name = self._loss_best(df)\n        print(f\"Computed split:\\nloss: {loss_best:.2f} (parent: {loss_parent:.2f})\\nattribute: {split_name}\\nthreshold: {split_threshold}\\ncount: {[len(df_.index) for df_ in split_df]}\")\n        if loss_best * self.splittyness < loss_parent:\n            print(f\"  => creating Node({split_name}, {split_threshold})\\n\")\n            branches = []\n            for i in range(2):\n                branches.append(self._node_or_leaf(split_df[i]))\n            item = Node(branches,split_name,split_threshold)\n        else:\n            item = self._leaf(df)\n        return item\n    \n    def _leaf(self,df):\n        unique, counts = np.unique(df[self.y_name].values,return_counts=True)\n        print([(unique[i], counts[i]) for i in range(len(counts))])\n        sort_ind = np.argsort(-counts)\n        value = unique[sort_ind[0]]\n        leaf = Leaf(value)\n        \n        # confusion matrix\n        i_predict = self.classes.index(value)\n        for i, c in enumerate(unique):\n            i_c = self.classes.index(c)\n            self.confusion_matrix[i_c,i_predict] += counts[i]\n        \n        print(f\"  => creating Leaf({value}, N={len(df.index)})\\n\")\n        return leaf\n    \n    def _loss_best(self,df):\n        loss0 = 10\n        for name in self.X_names:\n            if np.issubdtype(df[name].values.dtype, np.number):\n                #split_threshold_ = np.median(df[name].v\n                res = opt.minimize_scalar(self._opt_fun(df,name),bounds=(df[name].min(),df[name].max()),method=\"bounded\")\n                split_threshold_ = res.x\n                split_df_ = [df[df[name]<split_threshold_],\n                        df[df[name]>=split_threshold_]]\n                #loss = self._loss(split_df_[0]) + self._loss(split_df_[1])\n                loss = res.fun\n            else:\n                unique = np.unique(df[name])\n                split_threshold_ = [unique.ravel()[0]]\n                split_df_ =[df[df[name].isin(split_threshold_)],\n                            df[~df[name].isin(split_threshold_)]]\n                loss = self._loss(split_df_[0]) + self._loss(split_df_[1])\n            if loss < loss0:\n                loss0 = loss\n                split_threshold = split_threshold_\n                split_df = split_df_\n                split_name = name\n                \n        #print(loss0)\n                \n        return loss0, split_df, split_threshold, split_name\n    \n    def _loss(self,df):\n        #return self._gini_impurity(df)\n        return self._shannon_entropy(df)\n    \n    def metrics(self):\n        P = self._precision(self.confusion_matrix)\n        print(f\"precision: {P}\")\n        R = self._recall(self.confusion_matrix)\n        print(f\"recall: {R}\")\n        F = np.mean(self._F1(P,R))\n        print(f\"F-score: {F}\")\n        return {\"precision\":P,\n                \"recall\":R,\n                \"F-score\":F}\n    \n    @staticmethod\n    def _precision(m):\n        return np.diag(m) / np.sum(m, axis=1)\n        \n    \n    @staticmethod\n    def _recall(m):\n        return np.diag(m) / np.sum(m, axis=0)\n    \n    @staticmethod\n    def _F1(P,R):\n        #F = np.zeros_like(P)\n        #for i in range(len(\n        return 2 * P * R / (P + R)\n            \n        \n        ",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df=pd.read_csv(\"iris.csv\")",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df.columns\nX_names=[\"petal_length\",\"petal_width\"]\ndf[X_names]",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df.iloc[0]",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "c = CART(df,\"species\",X_names)\nc.create_tree(splittyness=1.)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "c.tree.predict(df.iloc[0]).value",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\ncolors = {\"setosa\":\"red\", \"versicolor\":\"blue\", \"virginica\":\"green\"}\nplt.scatter(df[\"petal_length\"],df[\"petal_width\"],c=df[\"species\"].map(colors))\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\nx, y = np.meshgrid(np.linspace(1,7,11),np.linspace(0,2.5,11))\ncol = []\nfor i in range(len(x.ravel())):\n    d = df.iloc[120].copy()\n    d[\"petal_length\"] = x.ravel()[i]\n    d[\"petal_width\"] = y.ravel()[i]\n    col.append(c.tree.predict(d).value)\nfor i in range(len(col)):\n    if col[i] == \"setosa\":\n        col[i] = 0\n    if col[i] == \"versicolor\":\n        col[i] = 1\n    if col[i] == \"virginica\":\n        col[i] = 2\nz = np.array(col).reshape(x.shape)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "fig, ax = plt.subplots()\nax.pcolormesh(x,y,z)\nax.scatter(df[\"petal_length\"],df[\"petal_width\"],c=df[\"species\"].map(colors))",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "c.confusion_matrix\nc.metrics()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "titanic = pd.read_csv(\"titanic.csv\")\ntitanic",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "titanic.columns",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\nc_titanic = CART(titanic,\"Survived\",[\"Pclass\",\"Age\",\"Fare\",\"Siblings/Spouses Aboard\",\"Sex\",\"Parents/Children Aboard\"])\nc_titanic.create_tree(splittyness=0.95)",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\nc_titanic.metrics()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "\npenguins = pd.read_csv(\"penguins.txt\").dropna()\npenguins.columns",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "penguins",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "c_penguins = CART(penguins,\"species\",[\"island\",\"bill_length_mm\",\"bill_depth_mm\",\"flipper_length_mm\",\"body_mass_g\",\"sex\"])",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "c_penguins.create_tree()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "c_penguins.metrics()",
      "metadata": {
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}